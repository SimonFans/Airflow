# airflow initdb
- Initialise the metadatabase

# airflow resetdb
- Reinitialize the metadatabase (Drop everything)

# airflow upgradedb
- Upgrade the metadatabase (Latest schemas, values, ...)

#airflow webserver
- Start Airflow’s webserver

#airflow scheduler
- Start Airflow’s scheduler

# airflow list_dags
- Give the list of known dags (either those in the examples folder or in dags folder)

# airflow worker
- Start a Celery worker (Useful in distributed mode to spread tasks among nodes - machines)

# airflow trigger_dag example_python_operator
- Trigger the dag example_python_operator with the current date as execution date

# airflow trigger_dag example_python_operator -e 2015-03-02
- Trigger the dag example_python_operator with a date in the past as execution date (This won’t trigger the tasks of that dag unless you set the option catchup=True in the DAG definition)

# airflow trigger_dag example_python_operator -e '2019-07-08 19:04:00+00:00'
- Trigger the dag example_python_operator with a date in the future (change the date here with one having +2 minutes later than the current date displayed in the Airflow UI). The dag will be scheduled at that date.

# airflow list_dag_runs example_python_operator
- Display the history of example_python_operator’s dag runs

# airflow list_tasks example_python_operator
- List the tasks contained into the example_python_operator dag

# airflow test example_python_operator print_the_context 2018-05-07
- Allow to test a task (print_the_context) from a given dag (example_python_operator here) without taking care of dependencies and past runs. Useful for debugging.

